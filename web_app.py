#!/usr/bin/env python3
"""
Cosmetic SEO Web Interface - Kullanƒ±cƒ± Dostu Aray√ºz
"""

from fastapi import FastAPI, Request, Form, BackgroundTasks
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
import asyncio
import os
import json
import time
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from loguru import logger
import uuid
from pathlib import Path

# Scraper'larƒ± import et
from real_scraper import RossmannScraper, SimpleSEOGenerator
from gratis_scraper import GratisScraper

load_dotenv()

app = FastAPI(title="üé≠ Cosmetic SEO Extractor", description="Kozmetik √ºr√ºnlerinden SEO bilgilerini √ßƒ±karƒ±n")

# Templates ve static dosyalar
templates = Jinja2Templates(directory="templates")
os.makedirs("static", exist_ok=True)
os.makedirs("templates", exist_ok=True)
app.mount("/static", StaticFiles(directory="static"), name="static")

# Global i≈ülem takibi
active_tasks = {}

class CosmeticSEOWebSystem:
    def __init__(self):
        self.results_dir = "data/web_results"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # Desteklenen siteler ve kategoriler
        self.sites = {
            "rossmann": {
                "name": "Rossmann",
                "categories": [
                    "y√ºz kremi", "g√ºne≈ü kremi", "nemlendirici", "serum", 
                    "makyaj", "ruj", "maskara", "fond√∂ten", "concealer",
                    "g√∂z kremi", "temizleyici", "tonik", "peeling", "maske"
                ]
            },
            "gratis": {
                "name": "Gratis",
                "categories": [
                    "y√ºz kremi", "g√ºne≈ü kremi", "nemlendirici", "serum",
                    "makyaj", "ruj", "maskara", "fond√∂ten", "concealer", 
                    "g√∂z kremi", "temizleyici", "tonik", "peeling", "maske",
                    "anti-aging", "vitamin c", "retinol", "hyaluronic acid"
                ]
            },
            "demo": {
                "name": "Demo Test (Hƒ±zlƒ±)",
                "categories": [
                    "serum", "krem", "maske", "vitamin", "bakƒ±m"
                ]
            }
        }
    
    async def process_request(self, task_id: str, site: str, category: str, max_products: int = 20):
        """Ana i≈ülem fonksiyonu"""
        try:
            active_tasks[task_id] = {
                "status": "starting",
                "progress": 0,
                "message": f"{site} sitesinde '{category}' aramasƒ± ba≈ülatƒ±lƒ±yor...",
                "results": [],
                "started_at": time.time()
            }
            
            if site == "demo":
                await self._process_demo(task_id, category, max_products)
            elif site == "rossmann":
                await self._process_rossmann(task_id, category, max_products)
            elif site == "gratis":
                await self._process_gratis(task_id, category, max_products)
            else:
                active_tasks[task_id]["status"] = "error"
                active_tasks[task_id]["message"] = f"{site} hen√ºz desteklenmiyor"
                
        except Exception as e:
            logger.error(f"Task {task_id} error: {e}")
            active_tasks[task_id]["status"] = "error"
            active_tasks[task_id]["message"] = f"Hata: {str(e)}"
    
    async def _process_demo(self, task_id: str, category: str, max_products: int):
        """Demo i≈üleme"""
        active_tasks[task_id].update({
            "status": "running",
            "progress": 10,
            "message": f"Demo veriler olu≈üturuluyor: {category}"
        })
        
        # Demo √ºr√ºnler
        demo_products = [
            {
                "name": f"Premium {category.title()} - Anti-Aging Formula",
                "brand": "BeautyLab",
                "price": "299.90 TL",
                "description": f"Yeni nesil {category} form√ºl√º. Premium ingredients ile zenginle≈ütirilmi≈ü.",
                "category": category,
                "url": f"https://demo.com/{category}-1"
            },
            {
                "name": f"Natural {category.title()} with Vitamin C",
                "brand": "GreenBeauty",
                "price": "189.90 TL", 
                "description": f"Doƒüal i√ßerikli {category}. Vitamin C ve E kompleksi i√ßerir.",
                "category": category,
                "url": f"https://demo.com/{category}-2"
            },
            {
                "name": f"Professional {category.title()} Solution",
                "brand": "ProCare",
                "price": "449.90 TL",
                "description": f"Profesyonel kalitede {category}. Dermatolog tavsiyeli form√ºl.",
                "category": category,
                "url": f"https://demo.com/{category}-3"
            }
        ]
        
        seo_generator = SimpleSEOGenerator()
        results = []
        
        for i, product in enumerate(demo_products[:max_products]):
            active_tasks[task_id].update({
                "progress": 30 + (i * 50 // len(demo_products)),
                "message": f"ƒ∞≈üleniyor: {product['name'][:30]}..."
            })
            
            # SEO verisi √ºret
            seo_data = seo_generator.generate_seo(product)
            quality_score = 85 + (i * 5)  # Demo i√ßin sabit skorlar
            
            result = {
                "product": product,
                "seo": seo_data,
                "quality_score": quality_score,
                "is_valid": True,
                "processed_at": time.time()
            }
            results.append(result)
            
            await asyncio.sleep(0.5)  # Demo i√ßin hƒ±z
        
        # Sonu√ßlarƒ± kaydet
        await self._save_results(task_id, results, f"demo_{category}")
        
        active_tasks[task_id].update({
            "status": "completed",
            "progress": 100,
            "message": f"‚úÖ {len(results)} √ºr√ºn ba≈üarƒ±yla i≈ülendi",
            "results": results
        })
    
    async def _process_rossmann(self, task_id: str, category: str, max_products: int):
        """Rossmann ger√ßek i≈üleme"""
        active_tasks[task_id].update({
            "status": "running", 
            "progress": 10,
            "message": f"Rossmann'da '{category}' aranƒ±yor..."
        })
        
        seo_generator = SimpleSEOGenerator()
        results = []
        
        async with RossmannScraper() as scraper:
            # URL'leri ke≈üfet
            active_tasks[task_id].update({
                "progress": 20,
                "message": "√úr√ºn URL'leri ke≈üfediliyor..."
            })
            
            urls = await scraper.discover_product_urls(category, max_products)
            
            if not urls:
                active_tasks[task_id].update({
                    "status": "completed",
                    "progress": 100,
                    "message": f"‚ö†Ô∏è '{category}' i√ßin √ºr√ºn bulunamadƒ±",
                    "results": []
                })
                return
            
            active_tasks[task_id].update({
                "progress": 30,
                "message": f"{len(urls)} √ºr√ºn bulundu, i≈üleniyor..."
            })
            
            # Her √ºr√ºn√º i≈üle
            for i, url in enumerate(urls):
                progress = 30 + (i * 60 // len(urls))
                active_tasks[task_id].update({
                    "progress": progress,
                    "message": f"ƒ∞≈üleniyor {i+1}/{len(urls)}: {url.split('/')[-1][:30]}..."
                })
                
                try:
                    # √úr√ºn verisini √ßek
                    product = await scraper.scrape_product(url)
                    
                    if "error" not in product:
                        # SEO verisi √ºret
                        seo_data = seo_generator.generate_seo(product)
                        quality_score = self._calculate_quality_score(product, seo_data)
                        
                        result = {
                            "product": product,
                            "seo": seo_data,
                            "quality_score": quality_score,
                            "is_valid": quality_score >= 70,
                            "processed_at": time.time()
                        }
                        results.append(result)
                
                except Exception as e:
                    logger.error(f"Error processing {url}: {e}")
                    continue
                
                await asyncio.sleep(2)  # Rate limiting
        
        # Sonu√ßlarƒ± kaydet
        await self._save_results(task_id, results, f"rossmann_{category}")
        
        valid_count = sum(1 for r in results if r["is_valid"])
        active_tasks[task_id].update({
            "status": "completed",
            "progress": 100,
            "message": f"‚úÖ {len(results)} √ºr√ºn i≈ülendi, {valid_count} ge√ßerli",
            "results": results
        })
    
    async def _process_gratis(self, task_id: str, category: str, max_products: int):
        """Gratis ger√ßek i≈üleme"""
        active_tasks[task_id].update({
            "status": "running", 
            "progress": 10,
            "message": f"Gratis'ta '{category}' aranƒ±yor..."
        })
        
        seo_generator = SimpleSEOGenerator()
        results = []
        
        async with GratisScraper() as scraper:
            # URL'leri ke≈üfet
            active_tasks[task_id].update({
                "progress": 20,
                "message": "Gratis'ta √ºr√ºn URL'leri ke≈üfediliyor..."
            })
            
            urls = await scraper.discover_product_urls(category, max_products)
            
            if not urls:
                active_tasks[task_id].update({
                    "status": "completed",
                    "progress": 100,
                    "message": f"‚ö†Ô∏è Gratis'ta '{category}' i√ßin √ºr√ºn bulunamadƒ±",
                    "results": []
                })
                return
            
            active_tasks[task_id].update({
                "progress": 30,
                "message": f"Gratis'ta {len(urls)} √ºr√ºn bulundu, i≈üleniyor..."
            })
            
            # Her √ºr√ºn√º i≈üle
            for i, url in enumerate(urls):
                progress = 30 + (i * 60 // len(urls))
                active_tasks[task_id].update({
                    "progress": progress,
                    "message": f"Gratis √ºr√ºn i≈üleniyor {i+1}/{len(urls)}: {url.split('/')[-1][:30]}..."
                })
                
                try:
                    # √úr√ºn verisini √ßek
                    product = await scraper.scrape_product(url)
                    
                    if "error" not in product:
                        # SEO verisi √ºret
                        seo_data = seo_generator.generate_seo(product)
                        quality_score = self._calculate_quality_score(product, seo_data)
                        
                        result = {
                            "product": product,
                            "seo": seo_data,
                            "quality_score": quality_score,
                            "is_valid": quality_score >= 70,
                            "processed_at": time.time()
                        }
                        results.append(result)
                
                except Exception as e:
                    logger.error(f"Error processing Gratis {url}: {e}")
                    continue
                
                await asyncio.sleep(2)  # Rate limiting
        
        # Sonu√ßlarƒ± kaydet
        await self._save_results(task_id, results, f"gratis_{category}")
        
        valid_count = sum(1 for r in results if r["is_valid"])
        active_tasks[task_id].update({
            "status": "completed",
            "progress": 100,
            "message": f"‚úÖ Gratis'tan {len(results)} √ºr√ºn i≈ülendi, {valid_count} ge√ßerli",
            "results": results
        })
    
    def _calculate_quality_score(self, product: Dict[str, Any], seo_data: Dict[str, Any]) -> int:
        """Kalite skoru hesapla"""
        score = 100
        
        if not product.get("name"):
            score -= 30
        if not product.get("price"):
            score -= 10
        if not product.get("description") or len(product.get("description", "")) < 50:
            score -= 20
        if not product.get("brand"):
            score -= 10
        
        keywords = seo_data.get("keywords", [])
        if len(keywords) < 3:
            score -= 15
        if len(seo_data.get("title", "")) > 60:
            score -= 5
        if len(seo_data.get("meta_description", "")) > 160:
            score -= 5
        
        return max(0, score)
    
    async def _save_results(self, task_id: str, results: List[Dict], filename_prefix: str):
        """Sonu√ßlarƒ± kaydet"""
        timestamp = int(time.time())
        
        # JSON kaydet
        json_file = f"{self.results_dir}/{filename_prefix}_{timestamp}.json"
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        # CSV kaydet
        csv_file = f"{self.results_dir}/{filename_prefix}_{timestamp}.csv"
        import csv
        with open(csv_file, "w", newline="", encoding="utf-8") as f:
            if results:
                writer = csv.writer(f)
                writer.writerow([
                    "product_name", "brand", "price", "primary_keyword", 
                    "keywords_count", "quality_score", "is_valid", "url"
                ])
                
                for result in results:
                    product = result["product"]
                    seo = result["seo"]
                    writer.writerow([
                        product.get("name", ""),
                        product.get("brand", ""),
                        product.get("price", ""),
                        seo.get("primary_keyword", ""),
                        len(seo.get("keywords", [])),
                        result.get("quality_score", 0),
                        result.get("is_valid", False),
                        product.get("url", "")
                    ])

# Global instance
seo_system = CosmeticSEOWebSystem()

@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    """Ana sayfa"""
    return templates.TemplateResponse("index.html", {
        "request": request,
        "sites": seo_system.sites
    })

@app.post("/extract")
async def start_extraction(
    background_tasks: BackgroundTasks,
    site: str = Form(...),
    category: str = Form(...),
    max_products: int = Form(20)
):
    """SEO √ßƒ±karƒ±mƒ±nƒ± ba≈ülat"""
    task_id = str(uuid.uuid4())
    
    # Background task ba≈ülat
    background_tasks.add_task(
        seo_system.process_request, 
        task_id, site, category, max_products
    )
    
    return JSONResponse({
        "task_id": task_id,
        "message": f"ƒ∞≈ülem ba≈ülatƒ±ldƒ±: {site} - {category}",
        "estimated_time": f"{max_products * 2} saniye"
    })

@app.get("/status/{task_id}")
async def get_task_status(task_id: str):
    """ƒ∞≈ülem durumunu getir"""
    if task_id not in active_tasks:
        return JSONResponse({"error": "Task bulunamadƒ±"}, status_code=404)
    
    return JSONResponse(active_tasks[task_id])

@app.get("/results/{task_id}")
async def get_results(task_id: str):
    """Sonu√ßlarƒ± getir"""
    if task_id not in active_tasks:
        return JSONResponse({"error": "Task bulunamadƒ±"}, status_code=404)
    
    task = active_tasks[task_id]
    if task["status"] != "completed":
        return JSONResponse({"error": "ƒ∞≈ülem hen√ºz tamamlanmadƒ±"}, status_code=400)
    
    return JSONResponse({
        "task_id": task_id,
        "total_products": len(task["results"]),
        "valid_products": sum(1 for r in task["results"] if r["is_valid"]),
        "results": task["results"]
    })

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=3000)