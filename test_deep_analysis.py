#!/usr/bin/env python3
"""
Test script to verify enhanced deep content analysis in analyzer agent
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from agents.analyzer_agent import DataCleaningTool
from config.models import ProductData

def test_deep_content_analysis():
    """Test the enhanced deep content analysis functionality"""
    
    # Create test product data with comprehensive content
    test_product = ProductData(
        url="https://example.com/sglam-brow-wax",
        site="example.com",
        name="SGLAM KaÅŸ Åekilendirici Brow Wax Premium Formula",
        brand="SGLAM",
        description="""
        Bu Ã¼rÃ¼n clinically tested ve dermatologically proven formÃ¼l ile geliÅŸtirilen advanced kaÅŸ ÅŸekilendirici wax'tÄ±r. 
        Scientifically formulated olan bu unique Ã¼rÃ¼n, professional salon quality sonuÃ§lar saÄŸlar.
        Long-lasting ve waterproof Ã¶zelliÄŸi ile tÃ¼m gÃ¼n mÃ¼kemmel gÃ¶rÃ¼nÃ¼m sunar.
        KaÅŸlarÄ±nÄ±zÄ± gently ÅŸekillendirir ve natural gÃ¶rÃ¼nÃ¼m kazandÄ±rÄ±r.
        Bu breakthrough technology ile Ã¼retilen innovative Ã¼rÃ¼n, lasting results sunar.
        
        Uzun aÃ§Ä±klama: Bu Ã¶zel formÃ¼lÃ¼, vitamin E ve natural botanical extracts iÃ§erir. 
        Retinol ve niacinamide gibi proven ingredients ile zenginleÅŸtirilmiÅŸtir.
        Research studies gÃ¶steriyor ki bu patented formula %95 oranÄ±nda effective sonuÃ§lar verir.
        """,
        price="89.90 TL",
        ingredients=["Vitamin E", "Retinol", "Niacinamide", "Botanical Extract", "Natural Wax"],
        features=["Waterproof", "Long-lasting", "Natural look", "Professional quality"],
        usage="GÃ¼nlÃ¼k kullanÄ±m iÃ§in sabah uygulanÄ±r. Clean skin Ã¼zerine gently massage yapÄ±n.",
        reviews=[
            "MÃ¼kemmel Ã¼rÃ¼n, really improves kaÅŸ gÃ¶rÃ¼nÃ¼mÃ¼",
            "Professional salon quality gerÃ§ekten",
            "Long-lasting sonuÃ§ veriyor"
        ]
    )
    
    print("ğŸ§ª Testing Enhanced Deep Content Analysis")
    print("=" * 60)
    
    try:
        # Create data cleaning tool instance
        tool = DataCleaningTool()
        
        # Test comprehensive content extraction
        full_content = tool._extract_comprehensive_content(test_product)
        print(f"ğŸ“„ Comprehensive Content Length: {len(full_content)} characters")
        print(f"ğŸ“„ First 200 chars: {full_content[:200]}...")
        print()
        
        # Test deep content analysis
        analysis = tool._perform_deep_content_analysis(full_content)
        print("ğŸ”¬ Deep Content Analysis Results:")
        print(f"   Word Count: {analysis['word_count']}")
        print(f"   Unique Word Ratio: {analysis['unique_word_ratio']}")
        print(f"   Scientific Authority: {analysis['scientific_authority']}")
        print(f"   Benefit Density: {analysis['benefit_density']}")
        print(f"   Quality Score: {analysis['quality_score']}/100")
        print(f"   Content Richness: {analysis['content_richness']}")
        print()
        
        # Test unique selling points
        usps = tool._identify_unique_selling_points(full_content)
        print("ğŸ’ Unique Selling Points:")
        for usp in usps:
            print(f"   - {usp}")
        print()
        
        # Test SEO content gaps
        gaps = tool._find_seo_content_gaps(full_content)
        print("ğŸ” SEO Content Opportunities:")
        for gap_type, gap_items in gaps.items():
            if gap_items:
                print(f"   {gap_type}: {', '.join(gap_items[:3])}")
        print()
        
        # Test scientific terms extraction
        sci_terms = tool._extract_scientific_terms(full_content)
        print("ğŸ”¬ Scientific Terms:")
        for term in sci_terms:
            print(f"   - {term}")
        print()
        
        # Test consumer benefits mapping
        benefits = tool._map_consumer_benefits(full_content)
        print("ğŸ’… Consumer Benefits Mapping:")
        for benefit_type, benefit_items in benefits.items():
            if benefit_items:
                print(f"   {benefit_type}: {', '.join(benefit_items)}")
        print()
        
        # Overall assessment
        if analysis['quality_score'] > 70:
            print("âœ… EXCELLENT: Deep analysis shows high-quality content suitable for superior SEO")
        elif analysis['quality_score'] > 40:
            print("âœ… GOOD: Deep analysis shows adequate content for professional SEO")
        else:
            print("âš ï¸  NEEDS IMPROVEMENT: Content requires enhancement for professional SEO")
        
        return True
        
    except Exception as e:
        print(f"âŒ ERROR in deep content analysis: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ Testing Enhanced Analyzer Agent Deep Content Analysis")
    print("=" * 60)
    
    success = test_deep_content_analysis()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ Deep content analysis test completed successfully!")
        print("\nğŸ“‹ Enhanced Features Verified:")
        print("âœ… Comprehensive content extraction from all product fields")
        print("âœ… Deep content quality analysis with scoring")
        print("âœ… Unique selling point identification")
        print("âœ… SEO content gap analysis")
        print("âœ… Scientific terminology extraction")
        print("âœ… Consumer benefits mapping")
        print("\nğŸŒŸ Ready for superior, professional SEO generation!")
    else:
        print("âš ï¸  Test failed - please check error messages above")